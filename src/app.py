import streamlit as st
import os
import sys

# å°†é¡¹ç›®è·¯å¾„åŠ å…¥ç³»ç»Ÿè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from rag_modules.retriever import CardioRetriever
from rag_modules.router import route_query
from rag_modules.generation import generate_answer  
import config

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="CardioGraphRAG", page_icon="ğŸ«€", layout="wide")

st.title("ğŸ«€ CardioGraphRAG: æ™ºèƒ½å¿ƒç”µåŠ©æ‰‹")
st.markdown(f"**Engine**: GraphRAG (Neo4j) + VectorRAG (FAISS) + {config.LLM_MODEL_NAME}")

# --- åˆå§‹åŒ– Session State ---
if "messages" not in st.session_state:
    st.session_state.messages = []

if "retriever" not in st.session_state:
    st.session_state.retriever = CardioRetriever()

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.header("ğŸ” ç³»ç»ŸçŠ¶æ€")
    st.success("âœ… FAISS å‘é‡åº“å·²è¿æ¥")
    st.success("âœ… Neo4j å›¾è°±å·²è¿æ¥")
    
    if st.button("æ¸…ç©ºå¯¹è¯"):
        st.session_state.messages = []
        st.rerun()

# --- æ ¸å¿ƒé€»è¾‘ ---
def get_bot_response(user_query):
    retriever = st.session_state.retriever
    
    # 1. è·¯ç”±ä¸æ£€ç´¢ UI å±•ç¤º
    with st.status("æ­£åœ¨æ€è€ƒ...", expanded=True) as status:
        st.write("ğŸ¤” åˆ†ææ„å›¾...")
        route = route_query(user_query)
        st.write(f"ğŸ‘‰ å†³ç­–: **{route.upper()}** æ¨¡å¼")
        
        st.write("ğŸ” æ£€ç´¢çŸ¥è¯†åº“...")
        contexts = retriever.hybrid_search(user_query, mode=route)
        
        # å¦‚æœæœ‰å›¾è°±ç»“æœï¼Œå±•ç¤ºç»™ç”¨æˆ·çœ‹ (å¢åŠ å¯è§£é‡Šæ€§)
        if contexts['graph_context']:
            with st.expander("æŸ¥çœ‹å›¾è°±æ¨ç†è·¯å¾„ (Knowledge Graph)"):
                st.code(contexts['graph_context'], language="text")
        
        status.update(label="æ£€ç´¢å®Œæˆ! æ­£åœ¨ç”Ÿæˆå›ç­”...", state="complete", expanded=False)
    
    # 2. ç”Ÿæˆå›ç­” (è°ƒç”¨ generation.py)
    return generate_answer(user_query, contexts)

# --- èŠå¤©ç•Œé¢æ¸²æŸ“ ---
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- å¤„ç†è¾“å…¥ ---
if prompt := st.chat_input("è¯·è¾“å…¥é—®é¢˜ (ä¾‹å¦‚: What causes AIVR?)"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        response = get_bot_response(prompt)
        st.markdown(response)
    
    st.session_state.messages.append({"role": "assistant", "content": response})